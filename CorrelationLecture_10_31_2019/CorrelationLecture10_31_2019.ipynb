{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Correlation\n",
    "\n",
    "This notebook will give you an opportunity to calculate correlation coefficients and develop an understanding of how to interpret the coefficient.  We're going to look at the Enviroscreen data, which includes data at the census tract level on a range of enviornmental hazards, health outcomes (e.g., asthma), and socioeconomic and demographic variables such as race and poverty.  I've provided an extract of the complete dataset below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call our libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import math\n",
    "from datascience import *\n",
    "\n",
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in our data, forcing the FIPS code to come in as a string\n",
    "dtype_dic= {'FIPS':str}\n",
    "ej_df=pd.read_csv('Enviroscreen_Extract.csv', delimiter = ',', dtype=dtype_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a look at the dataset\n",
    "ej_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Let's Plot the Data First\n",
    "\n",
    "Correlations are easy to visualize - we just set one variable as our x axis and one variable as our y axis.  We are going to call in the matplotlib library and specify the style we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ej_df[\"Poverty\"], ej_df[\"EnviroScore\"])\n",
    "plt.xlabel(\"Poverty\")\n",
    "plt.ylabel(\"EnviroScore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does look like there is a relationship, but it's also a lot of dots!  Let's create a new dataframe that only includes the census tracts for Alameda County."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ej_df.drop(ej_df[ej_df['County']!=\"Alameda\"].index, inplace = True)  \n",
    "ej_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened?  Why didn't it keep the Alameda rows?\n",
    "\n",
    "Unfortunately, sometimes when you import data from a previously formatted dataset like Enviroscreen, the .csv preserves blank spaces before or after a string variable.  Python requires the match to be exact, so it doesn't recognize \"  Alameda  \" as \"Alameda\".  Run the data import statement again above to re-import the raw data, and the run the code below and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code removes all the spaces from the county variable\n",
    "ej_df['County'] = ej_df['County'].str.strip()\n",
    "\n",
    "#Now, I can select my Alameda rows\n",
    "ej_df.drop(ej_df[ej_df['County']!=\"Alameda\"].index, inplace = True)  \n",
    "ej_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a scatterplot for the data for Alameda county here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eyeballing patterns is not the same as a statisical measure of a correlation; you must quantify it with numbers and statistics to prove your thoughts. Looking at the tables is not a very statistical measure of how much a variable correlates to the results. What does it mean for a variable \"income\" to match 7 out of the top 15 social disorder points? Does this correlate to the rest of the results? How well does it correlate? \n",
    "\n",
    "### 1.2 The correlation coefficient - *r*\n",
    "\n",
    "> The correlation coefficient ranges from −1 to 1. A value of 1 implies that a linear equation describes the relationship between X and Y perfectly, with all data points lying on a line for which Y increases as X increases. A value of −1 implies that all data points lie on a line for which Y decreases as X increases. A value of 0 implies that there is no linear correlation between the variables. ~Wikipedia\n",
    "\n",
    "*r* = 1: the scatter diagram is a perfect straight line sloping upwards\n",
    "\n",
    "*r* = -1: the scatter diagram is a perfect straight line sloping downwards.\n",
    "\n",
    "Let's calculate the correlation coefficient between poverty and the Enviroscreen score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ej_df['EnviroScore'].corr(ej_df[\"Poverty\"], method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ej_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's fit our line - for this, Python doesn't allow NANs, so we're going to delete census tracts with missing data.\n",
    "\n",
    "drop_na = ej_df.dropna()  # if not all census tracts have measure\n",
    "x = drop_na[\"Poverty\"]\n",
    "y = drop_na[\"EnviroScore\"]\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel(\"Poverty\", fontsize=18)\n",
    "plt.ylabel(\"EnviroScore\", fontsize=18)\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color=\"r\") #calculate line of best fit\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Getting P Values for Correlation\n",
    "\n",
    "It turns out that the pandas correlation function doesn't produce p-values automatically - you have to hard code them.  Instead, I found another cool library - pingouin - that has a super helpful correlation function.  Just like with researchpy, we need to install the library.\n",
    "\n",
    "Note that we learned that you can't put a # code in the same cell as pip install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.corr(x=ej_df['EnviroScore'], y=ej_df[\"Poverty\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If we want to get the p values for the whole matrix, the code is:\n",
    "ej_df.rcorr(stars=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What happens when you take out the stars=False code?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
